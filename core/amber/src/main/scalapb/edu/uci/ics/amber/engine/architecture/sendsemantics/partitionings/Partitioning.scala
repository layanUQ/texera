// Generated by the Scala Plugin for the Protocol Buffer Compiler.
// Do not edit!
//
// Protofile syntax: PROTO3

package edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings

sealed trait Partitioning extends scalapb.GeneratedSealedOneof {
  type MessageType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage
  final def isEmpty = this.isInstanceOf[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.Empty.type]
  final def isDefined = !isEmpty
  final def asMessage: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.PartitioningTypeMapper.toBase(this)
  final def asNonEmpty: Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty] = if (isEmpty) None else Some(this.asInstanceOf[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty])
}

object Partitioning {
  case object Empty extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning
  
  sealed trait NonEmpty extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning
  def defaultInstance: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning = Empty
  
  implicit val PartitioningTypeMapper: _root_.scalapb.TypeMapper[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning] = new _root_.scalapb.TypeMapper[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning] {
    override def toCustom(__base: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning = __base.sealedValue match {
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning => __v.value
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning => __v.value
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning => __v.value
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning => __v.value
      case edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty => Empty
    }
    override def toBase(__custom: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(__custom match {
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(__v)
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(__v)
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(__v)
      case __v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(__v)
      case Empty => edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty
    })
  }
}
@SerialVersionUID(0L)
final case class PartitioningMessage(
    sealedValue: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue
    ) extends scalapb.GeneratedMessage with scalapb.lenses.Updatable[PartitioningMessage] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      if (sealedValue.oneToOnePartitioning.isDefined) {
        val __value = sealedValue.oneToOnePartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (sealedValue.roundRobinPartitioning.isDefined) {
        val __value = sealedValue.roundRobinPartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (sealedValue.hashBasedShufflePartitioning.isDefined) {
        val __value = sealedValue.hashBasedShufflePartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      if (sealedValue.rangeBasedShufflePartitioning.isDefined) {
        val __value = sealedValue.rangeBasedShufflePartitioning.get
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      };
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      sealedValue.oneToOnePartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(1, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sealedValue.roundRobinPartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sealedValue.hashBasedShufflePartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(3, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      sealedValue.rangeBasedShufflePartitioning.foreach { __v =>
        val __m = __v
        _output__.writeTag(4, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
    }
    def getOneToOnePartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning = sealedValue.oneToOnePartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning.defaultInstance)
    def withOneToOnePartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(__v))
    def getRoundRobinPartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning = sealedValue.roundRobinPartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning.defaultInstance)
    def withRoundRobinPartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(__v))
    def getHashBasedShufflePartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning = sealedValue.hashBasedShufflePartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning.defaultInstance)
    def withHashBasedShufflePartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(__v))
    def getRangeBasedShufflePartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning = sealedValue.rangeBasedShufflePartitioning.getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning.defaultInstance)
    def withRangeBasedShufflePartitioning(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning): PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(__v))
    def clearSealedValue: PartitioningMessage = copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty)
    def withSealedValue(__v: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue): PartitioningMessage = copy(sealedValue = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => sealedValue.oneToOnePartitioning.orNull
        case 2 => sealedValue.roundRobinPartitioning.orNull
        case 3 => sealedValue.hashBasedShufflePartitioning.orNull
        case 4 => sealedValue.rangeBasedShufflePartitioning.orNull
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => sealedValue.oneToOnePartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 2 => sealedValue.roundRobinPartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 3 => sealedValue.hashBasedShufflePartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
        case 4 => sealedValue.rangeBasedShufflePartitioning.map(_.toPMessage).getOrElse(_root_.scalapb.descriptors.PEmpty)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage
    def toPartitioning: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.PartitioningTypeMapper.toCustom(this)
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.Partitioning])
}

object PartitioningMessage extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = {
    var __sealedValue: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 10 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(__sealedValue.oneToOnePartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 18 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(__sealedValue.roundRobinPartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 26 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(__sealedValue.hashBasedShufflePartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case 34 =>
          __sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(__sealedValue.rangeBasedShufflePartitioning.fold(_root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning](_input__))(_root_.scalapb.LiteParser.readMessage(_input__, _)))
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
        sealedValue = __sealedValue
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
        sealedValue = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(_))
            .orElse[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue](__fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(_)))
            .orElse[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue](__fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(_)))
            .orElse[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue](__fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).flatMap(_.as[_root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning]]).map(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(_)))
            .getOrElse(edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(0)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(0)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 1 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning
      case 2 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning
      case 3 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning
      case 4 => __out = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
    sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.Empty
  )
  sealed trait SealedValue extends _root_.scalapb.GeneratedOneof {
    def isEmpty: _root_.scala.Boolean = false
    def isDefined: _root_.scala.Boolean = true
    def isOneToOnePartitioning: _root_.scala.Boolean = false
    def isRoundRobinPartitioning: _root_.scala.Boolean = false
    def isHashBasedShufflePartitioning: _root_.scala.Boolean = false
    def isRangeBasedShufflePartitioning: _root_.scala.Boolean = false
    def oneToOnePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = _root_.scala.None
    def roundRobinPartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = _root_.scala.None
    def hashBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = _root_.scala.None
    def rangeBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = _root_.scala.None
  }
  object SealedValue {
    @SerialVersionUID(0L)
    case object Empty extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = _root_.scala.Nothing
      override def isEmpty: _root_.scala.Boolean = true
      override def isDefined: _root_.scala.Boolean = false
      override def number: _root_.scala.Int = 0
      override def value: _root_.scala.Nothing = throw new java.util.NoSuchElementException("Empty.value")
    }
  
    @SerialVersionUID(0L)
    final case class OneToOnePartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning
      override def isOneToOnePartitioning: _root_.scala.Boolean = true
      override def oneToOnePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = Some(value)
      override def number: _root_.scala.Int = 1
    }
    @SerialVersionUID(0L)
    final case class RoundRobinPartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning
      override def isRoundRobinPartitioning: _root_.scala.Boolean = true
      override def roundRobinPartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = Some(value)
      override def number: _root_.scala.Int = 2
    }
    @SerialVersionUID(0L)
    final case class HashBasedShufflePartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning
      override def isHashBasedShufflePartitioning: _root_.scala.Boolean = true
      override def hashBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = Some(value)
      override def number: _root_.scala.Int = 3
    }
    @SerialVersionUID(0L)
    final case class RangeBasedShufflePartitioning(value: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning) extends edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue {
      type ValueType = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning
      override def isRangeBasedShufflePartitioning: _root_.scala.Boolean = true
      override def rangeBasedShufflePartitioning: _root_.scala.Option[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = Some(value)
      override def number: _root_.scala.Int = 4
    }
  }
  implicit class PartitioningMessageLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage](_l) {
    def oneToOnePartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = field(_.getOneToOnePartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.OneToOnePartitioning(f_)))
    def roundRobinPartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = field(_.getRoundRobinPartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RoundRobinPartitioning(f_)))
    def hashBasedShufflePartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = field(_.getHashBasedShufflePartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.HashBasedShufflePartitioning(f_)))
    def rangeBasedShufflePartitioning: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = field(_.getRangeBasedShufflePartitioning)((c_, f_) => c_.copy(sealedValue = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue.RangeBasedShufflePartitioning(f_)))
    def sealedValue: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue] = field(_.sealedValue)((c_, f_) => c_.copy(sealedValue = f_))
  }
  final val ONETOONEPARTITIONING_FIELD_NUMBER = 1
  final val ROUNDROBINPARTITIONING_FIELD_NUMBER = 2
  final val HASHBASEDSHUFFLEPARTITIONING_FIELD_NUMBER = 3
  final val RANGEBASEDSHUFFLEPARTITIONING_FIELD_NUMBER = 4
  def of(
    sealedValue: edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage.SealedValue
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.PartitioningMessage(
    sealedValue
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.Partitioning])
}

@SerialVersionUID(0L)
final case class OneToOnePartitioning(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[OneToOnePartitioning] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      receivers.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      receivers.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
    }
    def withBatchSize(__v: _root_.scala.Int): OneToOnePartitioning = copy(batchSize = __v)
    def clearReceivers = copy(receivers = _root_.scala.Seq.empty)
    def addReceivers(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity*): OneToOnePartitioning = addAllReceivers(__vs)
    def addAllReceivers(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): OneToOnePartitioning = copy(receivers = receivers ++ __vs)
    def withReceivers(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): OneToOnePartitioning = copy(receivers = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => receivers
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(receivers.iterator.map(_.toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.OneToOnePartitioning])
}

object OneToOnePartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __receivers: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __receivers += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity](_input__)
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
        batchSize = __batchSize,
        receivers = __receivers.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        receivers = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(1)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(1)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
    batchSize = 0,
    receivers = _root_.scala.Seq.empty
  )
  implicit class OneToOnePartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def receivers: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]] = field(_.receivers)((c_, f_) => c_.copy(receivers = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val RECEIVERS_FIELD_NUMBER = 2
  def of(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.OneToOnePartitioning(
    batchSize,
    receivers
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.OneToOnePartitioning])
}

@SerialVersionUID(0L)
final case class RoundRobinPartitioning(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[RoundRobinPartitioning] {
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      receivers.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      receivers.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
    }
    def withBatchSize(__v: _root_.scala.Int): RoundRobinPartitioning = copy(batchSize = __v)
    def clearReceivers = copy(receivers = _root_.scala.Seq.empty)
    def addReceivers(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity*): RoundRobinPartitioning = addAllReceivers(__vs)
    def addAllReceivers(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): RoundRobinPartitioning = copy(receivers = receivers ++ __vs)
    def withReceivers(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): RoundRobinPartitioning = copy(receivers = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => receivers
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(receivers.iterator.map(_.toPMessage).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.RoundRobinPartitioning])
}

object RoundRobinPartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __receivers: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __receivers += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity](_input__)
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
        batchSize = __batchSize,
        receivers = __receivers.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        receivers = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(2)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(2)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
    batchSize = 0,
    receivers = _root_.scala.Seq.empty
  )
  implicit class RoundRobinPartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def receivers: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]] = field(_.receivers)((c_, f_) => c_.copy(receivers = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val RECEIVERS_FIELD_NUMBER = 2
  def of(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RoundRobinPartitioning(
    batchSize,
    receivers
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.RoundRobinPartitioning])
}

@SerialVersionUID(0L)
final case class HashBasedShufflePartitioning(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity],
    hashColumnIndices: _root_.scala.Seq[_root_.scala.Int]
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[HashBasedShufflePartitioning] {
    private[this] def hashColumnIndicesSerializedSize = {
      if (__hashColumnIndicesSerializedSizeField == 0) __hashColumnIndicesSerializedSizeField = {
        var __s: _root_.scala.Int = 0
        hashColumnIndices.foreach(__i => __s += _root_.com.google.protobuf.CodedOutputStream.computeInt32SizeNoTag(__i))
        __s
      }
      __hashColumnIndicesSerializedSizeField
    }
    @transient private[this] var __hashColumnIndicesSerializedSizeField: _root_.scala.Int = 0
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      receivers.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      if (hashColumnIndices.nonEmpty) {
        val __localsize = hashColumnIndicesSerializedSize
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__localsize) + __localsize
      }
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      receivers.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      if (hashColumnIndices.nonEmpty) {
        _output__.writeTag(3, 2)
        _output__.writeUInt32NoTag(hashColumnIndicesSerializedSize)
        hashColumnIndices.foreach(_output__.writeInt32NoTag)
      };
    }
    def withBatchSize(__v: _root_.scala.Int): HashBasedShufflePartitioning = copy(batchSize = __v)
    def clearReceivers = copy(receivers = _root_.scala.Seq.empty)
    def addReceivers(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity*): HashBasedShufflePartitioning = addAllReceivers(__vs)
    def addAllReceivers(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): HashBasedShufflePartitioning = copy(receivers = receivers ++ __vs)
    def withReceivers(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): HashBasedShufflePartitioning = copy(receivers = __v)
    def clearHashColumnIndices = copy(hashColumnIndices = _root_.scala.Seq.empty)
    def addHashColumnIndices(__vs: _root_.scala.Int*): HashBasedShufflePartitioning = addAllHashColumnIndices(__vs)
    def addAllHashColumnIndices(__vs: Iterable[_root_.scala.Int]): HashBasedShufflePartitioning = copy(hashColumnIndices = hashColumnIndices ++ __vs)
    def withHashColumnIndices(__v: _root_.scala.Seq[_root_.scala.Int]): HashBasedShufflePartitioning = copy(hashColumnIndices = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => receivers
        case 3 => hashColumnIndices
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(receivers.iterator.map(_.toPMessage).toVector)
        case 3 => _root_.scalapb.descriptors.PRepeated(hashColumnIndices.iterator.map(_root_.scalapb.descriptors.PInt(_)).toVector)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.HashBasedShufflePartitioning])
}

object HashBasedShufflePartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __receivers: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
    val __hashColumnIndices: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Int] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Int]
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __receivers += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity](_input__)
        case 24 =>
          __hashColumnIndices += _input__.readInt32()
        case 26 => {
          val length = _input__.readRawVarint32()
          val oldLimit = _input__.pushLimit(length)
          while (_input__.getBytesUntilLimit > 0) {
            __hashColumnIndices += _input__.readInt32()
          }
          _input__.popLimit(oldLimit)
        }
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
        batchSize = __batchSize,
        receivers = __receivers.result(),
        hashColumnIndices = __hashColumnIndices.result()
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        receivers = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]]).getOrElse(_root_.scala.Seq.empty),
        hashColumnIndices = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[_root_.scala.Int]]).getOrElse(_root_.scala.Seq.empty)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(3)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(3)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
    batchSize = 0,
    receivers = _root_.scala.Seq.empty,
    hashColumnIndices = _root_.scala.Seq.empty
  )
  implicit class HashBasedShufflePartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def receivers: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]] = field(_.receivers)((c_, f_) => c_.copy(receivers = f_))
    def hashColumnIndices: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Int]] = field(_.hashColumnIndices)((c_, f_) => c_.copy(hashColumnIndices = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val RECEIVERS_FIELD_NUMBER = 2
  final val HASHCOLUMNINDICES_FIELD_NUMBER = 3
  def of(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity],
    hashColumnIndices: _root_.scala.Seq[_root_.scala.Int]
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.HashBasedShufflePartitioning(
    batchSize,
    receivers,
    hashColumnIndices
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.HashBasedShufflePartitioning])
}

@SerialVersionUID(0L)
final case class RangeBasedShufflePartitioning(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity],
    rangeColumnIndices: _root_.scala.Seq[_root_.scala.Int],
    rangeMin: _root_.scala.Long,
    rangeMax: _root_.scala.Long
    ) extends scalapb.GeneratedMessage with edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.Partitioning.NonEmpty with scalapb.lenses.Updatable[RangeBasedShufflePartitioning] {
    private[this] def rangeColumnIndicesSerializedSize = {
      if (__rangeColumnIndicesSerializedSizeField == 0) __rangeColumnIndicesSerializedSizeField = {
        var __s: _root_.scala.Int = 0
        rangeColumnIndices.foreach(__i => __s += _root_.com.google.protobuf.CodedOutputStream.computeInt32SizeNoTag(__i))
        __s
      }
      __rangeColumnIndicesSerializedSizeField
    }
    @transient private[this] var __rangeColumnIndicesSerializedSizeField: _root_.scala.Int = 0
    @transient
    private[this] var __serializedSizeCachedValue: _root_.scala.Int = 0
    private[this] def __computeSerializedValue(): _root_.scala.Int = {
      var __size = 0
      
      {
        val __value = batchSize
        if (__value != 0) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt32Size(1, __value)
        }
      };
      receivers.foreach { __item =>
        val __value = __item
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__value.serializedSize) + __value.serializedSize
      }
      if (rangeColumnIndices.nonEmpty) {
        val __localsize = rangeColumnIndicesSerializedSize
        __size += 1 + _root_.com.google.protobuf.CodedOutputStream.computeUInt32SizeNoTag(__localsize) + __localsize
      }
      
      {
        val __value = rangeMin
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(4, __value)
        }
      };
      
      {
        val __value = rangeMax
        if (__value != 0L) {
          __size += _root_.com.google.protobuf.CodedOutputStream.computeInt64Size(5, __value)
        }
      };
      __size
    }
    override def serializedSize: _root_.scala.Int = {
      var read = __serializedSizeCachedValue
      if (read == 0) {
        read = __computeSerializedValue()
        __serializedSizeCachedValue = read
      }
      read
    }
    def writeTo(`_output__`: _root_.com.google.protobuf.CodedOutputStream): _root_.scala.Unit = {
      {
        val __v = batchSize
        if (__v != 0) {
          _output__.writeInt32(1, __v)
        }
      };
      receivers.foreach { __v =>
        val __m = __v
        _output__.writeTag(2, 2)
        _output__.writeUInt32NoTag(__m.serializedSize)
        __m.writeTo(_output__)
      };
      if (rangeColumnIndices.nonEmpty) {
        _output__.writeTag(3, 2)
        _output__.writeUInt32NoTag(rangeColumnIndicesSerializedSize)
        rangeColumnIndices.foreach(_output__.writeInt32NoTag)
      };
      {
        val __v = rangeMin
        if (__v != 0L) {
          _output__.writeInt64(4, __v)
        }
      };
      {
        val __v = rangeMax
        if (__v != 0L) {
          _output__.writeInt64(5, __v)
        }
      };
    }
    def withBatchSize(__v: _root_.scala.Int): RangeBasedShufflePartitioning = copy(batchSize = __v)
    def clearReceivers = copy(receivers = _root_.scala.Seq.empty)
    def addReceivers(__vs: edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity*): RangeBasedShufflePartitioning = addAllReceivers(__vs)
    def addAllReceivers(__vs: Iterable[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): RangeBasedShufflePartitioning = copy(receivers = receivers ++ __vs)
    def withReceivers(__v: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]): RangeBasedShufflePartitioning = copy(receivers = __v)
    def clearRangeColumnIndices = copy(rangeColumnIndices = _root_.scala.Seq.empty)
    def addRangeColumnIndices(__vs: _root_.scala.Int*): RangeBasedShufflePartitioning = addAllRangeColumnIndices(__vs)
    def addAllRangeColumnIndices(__vs: Iterable[_root_.scala.Int]): RangeBasedShufflePartitioning = copy(rangeColumnIndices = rangeColumnIndices ++ __vs)
    def withRangeColumnIndices(__v: _root_.scala.Seq[_root_.scala.Int]): RangeBasedShufflePartitioning = copy(rangeColumnIndices = __v)
    def withRangeMin(__v: _root_.scala.Long): RangeBasedShufflePartitioning = copy(rangeMin = __v)
    def withRangeMax(__v: _root_.scala.Long): RangeBasedShufflePartitioning = copy(rangeMax = __v)
    def getFieldByNumber(__fieldNumber: _root_.scala.Int): _root_.scala.Any = {
      (__fieldNumber: @_root_.scala.unchecked) match {
        case 1 => {
          val __t = batchSize
          if (__t != 0) __t else null
        }
        case 2 => receivers
        case 3 => rangeColumnIndices
        case 4 => {
          val __t = rangeMin
          if (__t != 0L) __t else null
        }
        case 5 => {
          val __t = rangeMax
          if (__t != 0L) __t else null
        }
      }
    }
    def getField(__field: _root_.scalapb.descriptors.FieldDescriptor): _root_.scalapb.descriptors.PValue = {
      _root_.scala.Predef.require(__field.containingMessage eq companion.scalaDescriptor)
      (__field.number: @_root_.scala.unchecked) match {
        case 1 => _root_.scalapb.descriptors.PInt(batchSize)
        case 2 => _root_.scalapb.descriptors.PRepeated(receivers.iterator.map(_.toPMessage).toVector)
        case 3 => _root_.scalapb.descriptors.PRepeated(rangeColumnIndices.iterator.map(_root_.scalapb.descriptors.PInt(_)).toVector)
        case 4 => _root_.scalapb.descriptors.PLong(rangeMin)
        case 5 => _root_.scalapb.descriptors.PLong(rangeMax)
      }
    }
    def toProtoString: _root_.scala.Predef.String = _root_.scalapb.TextFormat.printToSingleLineUnicodeString(this)
    def companion = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning
    // @@protoc_insertion_point(GeneratedMessage[edu.uci.ics.amber.engine.architecture.sendsemantics.RangeBasedShufflePartitioning])
}

object RangeBasedShufflePartitioning extends scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] {
  implicit def messageCompanion: scalapb.GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = this
  def parseFrom(`_input__`: _root_.com.google.protobuf.CodedInputStream): edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning = {
    var __batchSize: _root_.scala.Int = 0
    val __receivers: _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity] = new _root_.scala.collection.immutable.VectorBuilder[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]
    val __rangeColumnIndices: _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Int] = new _root_.scala.collection.immutable.VectorBuilder[_root_.scala.Int]
    var __rangeMin: _root_.scala.Long = 0L
    var __rangeMax: _root_.scala.Long = 0L
    var _done__ = false
    while (!_done__) {
      val _tag__ = _input__.readTag()
      _tag__ match {
        case 0 => _done__ = true
        case 8 =>
          __batchSize = _input__.readInt32()
        case 18 =>
          __receivers += _root_.scalapb.LiteParser.readMessage[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity](_input__)
        case 24 =>
          __rangeColumnIndices += _input__.readInt32()
        case 26 => {
          val length = _input__.readRawVarint32()
          val oldLimit = _input__.pushLimit(length)
          while (_input__.getBytesUntilLimit > 0) {
            __rangeColumnIndices += _input__.readInt32()
          }
          _input__.popLimit(oldLimit)
        }
        case 32 =>
          __rangeMin = _input__.readInt64()
        case 40 =>
          __rangeMax = _input__.readInt64()
        case tag => _input__.skipField(tag)
      }
    }
    edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
        batchSize = __batchSize,
        receivers = __receivers.result(),
        rangeColumnIndices = __rangeColumnIndices.result(),
        rangeMin = __rangeMin,
        rangeMax = __rangeMax
    )
  }
  implicit def messageReads: _root_.scalapb.descriptors.Reads[edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning] = _root_.scalapb.descriptors.Reads{
    case _root_.scalapb.descriptors.PMessage(__fieldsMap) =>
      _root_.scala.Predef.require(__fieldsMap.keys.forall(_.containingMessage eq scalaDescriptor), "FieldDescriptor does not match message type.")
      edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
        batchSize = __fieldsMap.get(scalaDescriptor.findFieldByNumber(1).get).map(_.as[_root_.scala.Int]).getOrElse(0),
        receivers = __fieldsMap.get(scalaDescriptor.findFieldByNumber(2).get).map(_.as[_root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]]).getOrElse(_root_.scala.Seq.empty),
        rangeColumnIndices = __fieldsMap.get(scalaDescriptor.findFieldByNumber(3).get).map(_.as[_root_.scala.Seq[_root_.scala.Int]]).getOrElse(_root_.scala.Seq.empty),
        rangeMin = __fieldsMap.get(scalaDescriptor.findFieldByNumber(4).get).map(_.as[_root_.scala.Long]).getOrElse(0L),
        rangeMax = __fieldsMap.get(scalaDescriptor.findFieldByNumber(5).get).map(_.as[_root_.scala.Long]).getOrElse(0L)
      )
    case _ => throw new RuntimeException("Expected PMessage")
  }
  def javaDescriptor: _root_.com.google.protobuf.Descriptors.Descriptor = PartitioningsProto.javaDescriptor.getMessageTypes().get(4)
  def scalaDescriptor: _root_.scalapb.descriptors.Descriptor = PartitioningsProto.scalaDescriptor.messages(4)
  def messageCompanionForFieldNumber(__number: _root_.scala.Int): _root_.scalapb.GeneratedMessageCompanion[_] = {
    var __out: _root_.scalapb.GeneratedMessageCompanion[_] = null
    (__number: @_root_.scala.unchecked) match {
      case 2 => __out = edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity
    }
    __out
  }
  lazy val nestedMessagesCompanions: Seq[_root_.scalapb.GeneratedMessageCompanion[_ <: _root_.scalapb.GeneratedMessage]] = Seq.empty
  def enumCompanionForFieldNumber(__fieldNumber: _root_.scala.Int): _root_.scalapb.GeneratedEnumCompanion[_] = throw new MatchError(__fieldNumber)
  lazy val defaultInstance = edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
    batchSize = 0,
    receivers = _root_.scala.Seq.empty,
    rangeColumnIndices = _root_.scala.Seq.empty,
    rangeMin = 0L,
    rangeMax = 0L
  )
  implicit class RangeBasedShufflePartitioningLens[UpperPB](_l: _root_.scalapb.lenses.Lens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning]) extends _root_.scalapb.lenses.ObjectLens[UpperPB, edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning](_l) {
    def batchSize: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Int] = field(_.batchSize)((c_, f_) => c_.copy(batchSize = f_))
    def receivers: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity]] = field(_.receivers)((c_, f_) => c_.copy(receivers = f_))
    def rangeColumnIndices: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Seq[_root_.scala.Int]] = field(_.rangeColumnIndices)((c_, f_) => c_.copy(rangeColumnIndices = f_))
    def rangeMin: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.rangeMin)((c_, f_) => c_.copy(rangeMin = f_))
    def rangeMax: _root_.scalapb.lenses.Lens[UpperPB, _root_.scala.Long] = field(_.rangeMax)((c_, f_) => c_.copy(rangeMax = f_))
  }
  final val BATCHSIZE_FIELD_NUMBER = 1
  final val RECEIVERS_FIELD_NUMBER = 2
  final val RANGECOLUMNINDICES_FIELD_NUMBER = 3
  final val RANGEMIN_FIELD_NUMBER = 4
  final val RANGEMAX_FIELD_NUMBER = 5
  def of(
    batchSize: _root_.scala.Int,
    receivers: _root_.scala.Seq[edu.uci.ics.amber.engine.common.virtualidentity.ActorVirtualIdentity],
    rangeColumnIndices: _root_.scala.Seq[_root_.scala.Int],
    rangeMin: _root_.scala.Long,
    rangeMax: _root_.scala.Long
  ): _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning = _root_.edu.uci.ics.amber.engine.architecture.sendsemantics.partitionings.RangeBasedShufflePartitioning(
    batchSize,
    receivers,
    rangeColumnIndices,
    rangeMin,
    rangeMax
  )
  // @@protoc_insertion_point(GeneratedMessageCompanion[edu.uci.ics.amber.engine.architecture.sendsemantics.RangeBasedShufflePartitioning])
}
